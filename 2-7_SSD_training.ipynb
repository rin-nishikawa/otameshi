{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRDrOClOJvlA"
      },
      "source": [
        "# 2.7 学習と検証の実施\n",
        "\n",
        "- 本ファイルでは、SSDの学習と検証の実施を行います。手元のマシンで動作を確認後、AWSのGPUマシンで計算します。\n",
        "- p2.xlargeで約6時間かかります。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQkSZ3f7JvlH"
      },
      "source": [
        "# 学習目標\n",
        "\n",
        "1.\tSSDの学習を実装できるようになる"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/rin-nishikawa/otameshi.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd \"otameshi\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tarfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# フォルダ「data」が存在しない場合は作成する\n",
        "data_dir = \"./data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# フォルダ「weights」が存在しない場合は作成する\n",
        "weights_dir = \"./weights/\"\n",
        "if not os.path.exists(weights_dir):\n",
        "    os.mkdir(weights_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VOC2012のデータセットをここからダウンロードします\n",
        "# 時間がかかります（約15分）\n",
        "url = \"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\"\n",
        "target_path = os.path.join(data_dir, \"VOCtrainval_11-May-2012.tar\") \n",
        "\n",
        "if not os.path.exists(target_path):\n",
        "    urllib.request.urlretrieve(url, target_path)\n",
        "    \n",
        "    tar = tarfile.TarFile(target_path)  # tarファイルを読み込み\n",
        "    tar.extractall(data_dir)  # tarを解凍\n",
        "    tar.close()  # tarファイルをクローズ\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習済みのSSD用のVGGのパラメータをフォルダ「weights」にダウンロード\n",
        "# MIT License\n",
        "# Copyright (c) 2017 Max deGroot, Ellis Brown\n",
        "# https://github.com/amdegroot/ssd.pytorch\n",
        "    \n",
        "url = \"https://s3.amazonaws.com/amdegroot-models/vgg16_reducedfc.pth\"\n",
        "target_path = os.path.join(weights_dir, \"vgg16_reducedfc.pth\") \n",
        "\n",
        "if not os.path.exists(target_path):\n",
        "    urllib.request.urlretrieve(url, target_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習済みのSSD300モデルをフォルダ「weights」にダウンロード\n",
        "# MIT License\n",
        "# Copyright (c) 2017 Max deGroot, Ellis Brown\n",
        "# https://github.com/amdegroot/ssd.pytorch\n",
        "\n",
        "url = \"https://s3.amazonaws.com/amdegroot-models/ssd300_mAP_77.43_v2.pth\"\n",
        "target_path = os.path.join(weights_dir, \"ssd300_mAP_77.43_v2.pth\") \n",
        "\n",
        "if not os.path.exists(target_path):\n",
        "    urllib.request.urlretrieve(url, target_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-pUmMgPJvlI"
      },
      "source": [
        "# 事前準備\n",
        "\n",
        "- AWS EC2 のGPUインスタンスを使用します\n",
        "- フォルダ「utils」のssd_model.pyをします"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5wFXuAjsJvlI"
      },
      "outputs": [],
      "source": [
        "# パッケージのimport\n",
        "import os.path as osp\n",
        "import random\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MKIiLcdZJvlJ"
      },
      "outputs": [],
      "source": [
        "# 乱数のシードを設定\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fNcYx2L0JvlK",
        "outputId": "c2e8ec71-fb0c-4dd1-f05c-a1e6bf500a8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "使用デバイス： cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"使用デバイス：\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2hwPVpFJvlK"
      },
      "source": [
        "# DatasetとDataLoaderを作成する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9scicyiOJvlL"
      },
      "outputs": [],
      "source": [
        "from utils.ssd_model import make_datapath_list, VOCDataset, DataTransform, Anno_xml2list, od_collate_fn\n",
        "\n",
        "\n",
        "# ファイルパスのリストを取得\n",
        "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
        "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
        "    rootpath)\n",
        "\n",
        "# Datasetを作成\n",
        "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
        "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
        "               'cow', 'diningtable', 'dog', 'horse',\n",
        "               'motorbike', 'person', 'pottedplant',\n",
        "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "color_mean = (104, 117, 123)  # (BGR)の色の平均値\n",
        "input_size = 300  # 画像のinputサイズを300×300にする\n",
        "\n",
        "#なぜかRandomSampleCropがうまくいかなかったのでコメントアウト\n",
        "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(\n",
        "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
        "\n",
        "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n",
        "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
        "\n",
        "\n",
        "# DataLoaderを作成する\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn)\n",
        "\n",
        "val_dataloader = data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False, collate_fn=od_collate_fn)\n",
        "\n",
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbyl0KAwJvlL"
      },
      "source": [
        "# ネットワークモデルの作成する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4dFZ6oVjJvlM",
        "outputId": "6e7542ee-79e0-412d-afcd-342f6927eb57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "使用デバイス： cpu\n",
            "ネットワーク設定完了：学習済みの重みをロードしました\n"
          ]
        }
      ],
      "source": [
        "from utils.ssd_model import SSD\n",
        "\n",
        "# SSD300の設定\n",
        "ssd_cfg = {\n",
        "    'num_classes': 21,  # 背景クラスを含めた合計クラス数\n",
        "    'input_size': 300,  # 画像の入力サイズ\n",
        "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # 出力するDBoxのアスペクト比の種類\n",
        "    'feature_maps': [38, 19, 10, 5, 3, 1],  # 各sourceの画像サイズ\n",
        "    'steps': [8, 16, 32, 64, 100, 300],  # DBOXの大きさを決める\n",
        "    'min_sizes': [30, 60, 111, 162, 213, 264],  # DBOXの大きさを決める\n",
        "    'max_sizes': [60, 111, 162, 213, 264, 315],  # DBOXの大きさを決める\n",
        "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
        "}\n",
        "\n",
        "# SSDネットワークモデル\n",
        "net = SSD(phase=\"train\", cfg=ssd_cfg)\n",
        "\n",
        "# SSDの初期の重みを設定\n",
        "# ssdのvgg部分に重みをロードする\n",
        "vgg_weights = torch.load('./weights/vgg16_reducedfc.pth')\n",
        "net.vgg.load_state_dict(vgg_weights)\n",
        "\n",
        "# ssdのその他のネットワークの重みはHeの初期値で初期化\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        init.kaiming_normal_(m.weight.data)\n",
        "        if m.bias is not None:  # バイアス項がある場合\n",
        "            nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "\n",
        "# Heの初期値を適用\n",
        "net.extras.apply(weights_init)\n",
        "net.loc.apply(weights_init)\n",
        "net.conf.apply(weights_init)\n",
        "\n",
        "# GPUが使えるかを確認\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"使用デバイス：\", device)\n",
        "\n",
        "print('ネットワーク設定完了：学習済みの重みをロードしました')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5tGwXegJvlM"
      },
      "source": [
        "# 損失関数と最適化手法を定義する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IkZq2BPeJvlM"
      },
      "outputs": [],
      "source": [
        "from utils.ssd_model import MultiBoxLoss\n",
        "\n",
        "# 損失関数の設定\n",
        "criterion = MultiBoxLoss(jaccard_thresh=0.5, neg_pos=3, device=device)\n",
        "\n",
        "# 最適化手法の設定\n",
        "optimizer = optim.SGD(net.parameters(), lr=1e-3,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXpicFdQJvlN"
      },
      "source": [
        "# 学習・検証を実施する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h5BNcGMKJvlN"
      },
      "outputs": [],
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # イテレーションカウンタをセット\n",
        "    iteration = 1\n",
        "    epoch_train_loss = 0.0  # epochの損失和\n",
        "    epoch_val_loss = 0.0  # epochの損失和\n",
        "    logs = []\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs+1):\n",
        "\n",
        "        # 開始時刻を保存\n",
        "        t_epoch_start = time.time()\n",
        "        t_iter_start = time.time()\n",
        "\n",
        "        print('-------------')\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-------------')\n",
        "\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "                print('（train）')\n",
        "            else:\n",
        "                if((epoch+1) % 10 == 0):\n",
        "                    net.eval()   # モデルを検証モードに\n",
        "                    print('-------------')\n",
        "                    print('（val）')\n",
        "                else:\n",
        "                    # 検証は10回に1回だけ行う\n",
        "                    continue\n",
        "\n",
        "            # データローダーからminibatchずつ取り出すループ\n",
        "            for images, targets in dataloaders_dict[phase]:\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                images = images.to(device)\n",
        "                targets = [ann.to(device)\n",
        "                           for ann in targets]  # リストの各要素のテンソルをGPUへ\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # 順伝搬（forward）計算\n",
        "                    outputs = net(images)\n",
        "\n",
        "                    # 損失の計算\n",
        "                    loss_l, loss_c = criterion(outputs, targets)\n",
        "                    loss = loss_l + loss_c\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()  # 勾配の計算\n",
        "\n",
        "                        # 勾配が大きくなりすぎると計算が不安定になるので、clipで最大でも勾配2.0に留める\n",
        "                        nn.utils.clip_grad_value_(\n",
        "                            net.parameters(), clip_value=2.0)\n",
        "\n",
        "                        optimizer.step()  # パラメータ更新\n",
        "\n",
        "                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
        "                            t_iter_finish = time.time()\n",
        "                            duration = t_iter_finish - t_iter_start\n",
        "                            print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n",
        "                                iteration, loss.item(), duration))\n",
        "                            t_iter_start = time.time()\n",
        "\n",
        "                        epoch_train_loss += loss.item()\n",
        "                        iteration += 1\n",
        "\n",
        "                    # 検証時\n",
        "                    else:\n",
        "                        epoch_val_loss += loss.item()\n",
        "\n",
        "        # epochのphaseごとのloss （Issue158での誤植修正）\n",
        "        t_epoch_finish = time.time()\n",
        "        print('-------------')\n",
        "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
        "            epoch+1, epoch_train_loss, epoch_val_loss))\n",
        "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
        "        t_epoch_start = time.time()\n",
        "\n",
        "        # ログを保存\n",
        "        log_epoch = {'epoch': epoch+1,\n",
        "                     'train_loss': epoch_train_loss, 'val_loss': epoch_val_loss}\n",
        "        logs.append(log_epoch)\n",
        "        df = pd.DataFrame(logs)\n",
        "        df.to_csv(\"log_output.csv\")\n",
        "\n",
        "        epoch_train_loss = 0.0  # epochの損失和\n",
        "        epoch_val_loss = 0.0  # epochの損失和\n",
        "\n",
        "        # ネットワークを保存する\n",
        "        if ((epoch+1) % 10 == 0):\n",
        "            torch.save(net.state_dict(), 'weights/ssd300_' +\n",
        "                       str(epoch+1) + '.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BuOV3vkiJvlO",
        "outputId": "0a817057-95b0-4c31-f25a-9649d1d21a2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "使用デバイス： cpu\n",
            "-------------\n",
            "Epoch 1/50\n",
            "-------------\n",
            "（train）\n",
            "イテレーション 10 || Loss: 16.3035 || 10iter: 268.4300 sec.\n"
          ]
        }
      ],
      "source": [
        "# 学習・検証を実行する\n",
        "num_epochs= 50  \n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)\n",
        "#1ep８分以上かかっていたので無理そう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAXU63BxJvlP"
      },
      "source": [
        "# 推論"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2  # OpenCVライブラリ\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.ssd_model import SSD\n",
        "\n",
        "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
        "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
        "               'cow', 'diningtable', 'dog', 'horse',\n",
        "               'motorbike', 'person', 'pottedplant',\n",
        "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "\n",
        "# SSD300の設定\n",
        "ssd_cfg = {\n",
        "    'num_classes': 21,  # 背景クラスを含めた合計クラス数\n",
        "    'input_size': 300,  # 画像の入力サイズ\n",
        "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # 出力するDBoxのアスペクト比の種類\n",
        "    'feature_maps': [38, 19, 10, 5, 3, 1],  # 各sourceの画像サイズ\n",
        "    'steps': [8, 16, 32, 64, 100, 300],  # DBOXの大きさを決める\n",
        "    'min_sizes': [30, 60, 111, 162, 213, 264],  # DBOXの大きさを決める\n",
        "    'max_sizes': [60, 111, 162, 213, 264, 315],  # DBOXの大きさを決める\n",
        "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
        "}\n",
        "\n",
        "# SSDネットワークモデル\n",
        "net = SSD(phase=\"inference\", cfg=ssd_cfg)\n",
        "\n",
        "# SSDの学習済みの重みを設定\n",
        "net_weights = torch.load('./weights/ssd300_50.pth',\n",
        "                         map_location={'cuda:0': 'cpu'})\n",
        "\n",
        "#net_weights = torch.load('./weights/ssd300_mAP_77.43_v2.pth',\n",
        "#                         map_location={'cuda:0': 'cpu'})\n",
        "\n",
        "net.load_state_dict(net_weights)\n",
        "\n",
        "print('ネットワーク設定完了：学習済みの重みをロードしました')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.ssd_model import DataTransform\n",
        "\n",
        "# 1. 画像読み込み\n",
        "image_file_path = \"./data/cowboy-757575_640.jpg\"\n",
        "img = cv2.imread(image_file_path)  # [高さ][幅][色BGR]\n",
        "height, width, channels = img.shape  # 画像のサイズを取得\n",
        "\n",
        "# 2. 元画像の表示\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.show()\n",
        "\n",
        "# 3. 前処理クラスの作成\n",
        "color_mean = (104, 117, 123)  # (BGR)の色の平均値\n",
        "input_size = 300  # 画像のinputサイズを300×300にする\n",
        "transform = DataTransform(input_size, color_mean)\n",
        "\n",
        "# 4. 前処理\n",
        "phase = \"val\"\n",
        "img_transformed, boxes, labels = transform(\n",
        "    img, phase, \"\", \"\")  # アノテーションはないので、\"\"にする\n",
        "img = torch.from_numpy(img_transformed[:, :, (2, 1, 0)]).permute(2, 0, 1)\n",
        "\n",
        "# 5. SSDで予測\n",
        "net.eval()  # ネットワークを推論モードへ\n",
        "x = img.unsqueeze(0)  # ミニバッチ化：torch.Size([1, 3, 300, 300])\n",
        "detections = net(x)\n",
        "\n",
        "print(detections.shape)\n",
        "print(detections)\n",
        "\n",
        "# output : torch.Size([batch_num, 21, 200, 5])\n",
        "#  =（batch_num、クラス、confのtop200、規格化されたBBoxの情報）\n",
        "#   規格化されたBBoxの情報（確信度、xmin, ymin, xmax, ymax）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 画像に対する予測\n",
        "from utils.ssd_predict_show import SSDPredictShow\n",
        "\n",
        "# ファイルパス\n",
        "image_file_path = \"./data/cowboy-757575_640.jpg\"\n",
        "\n",
        "# 予測と、予測結果を画像で描画する\n",
        "ssd = SSDPredictShow(eval_categories=voc_classes, net=net)\n",
        "ssd.show(image_file_path, data_confidence_level=0.6)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "2-7_SSD_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
